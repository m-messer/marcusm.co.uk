---
---
Publications
==========


@inproceedings{10.1007/978-3-031-64302-6_8,
	abstract = {Professional developers, and especially students learning to program, often write poor documentation. While automated assessment for programming is becoming more common in educational settings, often using unit tests for code functionality and static analysis for code quality, documentation assessment is typically limited to detecting the presence and the correct formatting of a docstring based on a specified style guide. We aim to investigate how machine learning can be utilised to aid in automating the assessment of documentation quality. We classify a large set of publicly available human-annotated relevance scores between a natural language string and a code string, using traditional approaches, such as Logistic Regression and Random Forest, fine-tuned large language models, such as BERT and GPT, and Low-Rank Adaptation of large language models. Our most accurate mode was a fine-tuned CodeBERT model, resulting in a test accuracy of 89{\%}.},
	address = {Cham},
	author = {Messer, Marcus and Shi, Miaojing and Brown, Neil C. C. and K{\"o}lling, Michael},
	booktitle = {Artificial Intelligence in Education},
	editor = {Olney, Andrew M. and Chounta, Irene-Angelica and Liu, Zitao and Santos, Olga C. and Bittencourt, Ig Ibert},
	isbn = {978-3-031-64302-6},
	pages = {105--117},
	publisher = {Springer Nature Switzerland},
	title = {Grading Documentation with Machine Learning},
	year = {2024}}
